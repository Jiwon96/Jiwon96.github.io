---
layout: post
title: "프로세스 & 스케줄링 완전 정리"
date: 2024-07-25
categories: [CS, OS]
tags: [프로세스, 스케줄링, 컨텍스트스위칭, 메모리관리, 운영체제]
---

# 프로세스 & 스케줄링 완전 정리

## 1. 프로세스의 기본 개념과 구조

### 1.1 프로그램에서 프로세스로의 변화

**프로그램**은 하드디스크에 저장된 실행 파일로, 아직 실행되지 않은 정적인 상태입니다. 반면 **프로세스**는 이 프로그램이 메모리에 적재되어 CPU에 의해 실행되고 있는 동적인 상태를 의미합니다.

이러한 변화 과정에서 운영체제는 각 프로세스에게 **고유한 PID(Process ID)**를 부여하고, **독립적인 메모리 공간**을 할당합니다. 이는 여러 프로세스가 동시에 실행되더라도 서로 간섭하지 않도록 보장하는 핵심 메커니즘입니다.

```
실생활 예시:
프로그램 = 요리책 (책장에 있는 상태)
프로세스 = 요리책을 보고 실제로 요리하는 행위
스레드 = 한 요리를 만들기 위해 동시에 일하는 여러 요리사들
```

### 1.2 프로세스와 스레드의 관계

프로세스가 공장이라면, **스레드**는 그 공장 안에서 일하는 작업자들입니다. 하나의 프로세스 안에 여러 개의 스레드가 존재할 수 있으며, 이들은 프로세스의 자원을 공유하면서 동시에 작업을 수행합니다.

**핵심 차이점**:
- **프로세스**: 독립적인 메모리 공간, 높은 생성 비용, 안전한 격리
- **스레드**: 메모리 공간 공유, 낮은 생성 비용, 빠른 통신

### 1.3 프로세스 상태의 생명주기

프로세스는 생성부터 종료까지 다음과 같은 상태를 거칩니다:

1. **New (생성)**: 프로세스가 막 생성되어 시스템에 등록된 상태
2. **Ready (준비)**: CPU를 할당받기를 기다리는 상태
3. **Running (실행)**: CPU를 할당받아 명령어를 실행하는 상태
4. **Waiting (대기)**: I/O 작업이나 특정 이벤트를 기다리는 상태  
5. **Terminated (종료)**: 실행이 완료되어 시스템에서 제거되기를 기다리는 상태

```
은행 업무 처리 과정으로 비유:
New: 은행에 들어와서 번호표를 뽑은 상태
Ready: 대기줄에서 순서를 기다리는 상태
Running: 창구에서 업무를 처리하는 상태
Waiting: 서류를 가져오러 잠시 자리를 비운 상태
Terminated: 업무를 마치고 은행을 나가는 상태
```

현대 운영체제에서는 **메모리 부족 시 Suspended 상태**가 추가되어 7-state 모델을 사용합니다:
- **Ready/Suspended**: Ready 상태이지만 메모리에서 스왑아웃된 상태
- **Waiting/Suspended**: Waiting 상태이면서 메모리에서 스왑아웃된 상태

### 1.4 PCB(Process Control Block)의 구조

**PCB**는 각 프로세스의 모든 정보를 담고 있는 운영체제의 핵심 자료구조입니다:

```c
struct PCB {
    // 프로세스 식별 정보
    int process_id;                    // PID
    int parent_process_id;             // PPID
    int process_state;                 // NEW, READY, RUNNING, WAITING, TERMINATED
    
    // CPU 컨텍스트 정보
    struct cpu_context {
        unsigned long registers[16];    // 범용 레지스터들
        unsigned long program_counter;  // PC (다음 실행할 명령어 주소)
        unsigned long stack_pointer;    // SP (스택의 현재 위치)
        unsigned long status_register;  // 플래그 레지스터
    } cpu_context;
    
    // 메모리 관리 정보
    struct memory_info {
        unsigned long code_start, code_end;
        unsigned long data_start, data_end;
        unsigned long heap_start, heap_end;
        unsigned long stack_start, stack_end;
    } memory_info;
    
    // 스케줄링 정보
    int priority;
    int time_quantum_left;
    
    // I/O 및 파일 정보
    struct file_descriptor_table *files;
};
```

**스레드의 경우 TCB(Thread Control Block)**를 사용하며, 프로세스의 메모리 정보는 공유하고 **레지스터와 스택 정보만 독립적**으로 가집니다.

### 1.5 리눅스에서의 프로세스 관리

리눅스에서는 **fork() 시스템 콜**로 프로세스를 생성하고, **exec() 계열 함수**로 새로운 프로그램을 실행합니다. 스레드는 **pthread 라이브러리**나 **clone() 시스템 콜**을 사용합니다.

**좀비 프로세스**는 자식이 종료되었지만 부모가 **wait() 시스템 콜**을 호출하지 않아 PCB가 남아있는 상태입니다. **고아 프로세스**는 부모가 먼저 죽어서 **init 프로세스(PID 1)**가 새로운 부모가 되는 프로세스입니다.

**데몬 프로세스**는 백그라운드에서 지속적으로 실행되는 시스템 서비스로, 터미널과 분리되어 init의 자식으로 실행됩니다.

## 2. 프로세스 주소공간의 구조와 관리

### 2.1 가상 주소공간의 4가지 영역

각 프로세스는 독립적인 **가상 주소공간**을 가지며, 이는 용도에 따라 4개 영역으로 구분됩니다:

```
높은 주소 (0xFFFFFFFF)
┌─────────────────────┐
│      Stack          │ ← 지역변수, 함수 매개변수, 리턴 주소
│        ↓            │   (아래 방향으로 성장)
├─────────────────────┤
│     빈 공간         │ ← Stack과 Heap이 만나면 Stack Overflow
│        ↑            │
├─────────────────────┤  
│      Heap           │ ← 동적 할당 메모리 (malloc, new)
├─────────────────────┤   (위 방향으로 성장)
│      Data           │ ← 전역변수, 정적변수
│  ┌─────────────────┐│
│  │ Initialized Data││ ← int global = 10;
│  ├─────────────────┤│
│  │  BSS Segment    ││ ← int uninitialized; (자동으로 0)
│  └─────────────────┘│
├─────────────────────┤
│      Code           │ ← 프로그램 실행 코드 (읽기 전용)
└─────────────────────┘
낮은 주소 (0x00000000)
```

### 2.2 각 영역의 특성과 역할

**Code 영역**은 프로그램의 실행 코드가 들어있는 **읽기 전용** 영역입니다. 같은 프로그램을 실행하는 여러 프로세스가 이 영역을 공유할 수 있어 메모리를 절약합니다.

**Data 영역**은 두 부분으로 나뉩니다:
- **Initialized Data**: 초기값이 있는 전역변수와 정적변수
- **BSS(Block Started by Symbol)**: 초기화되지 않은 전역변수와 정적변수 (자동으로 0으로 초기화)

**Heap 영역**은 **동적 메모리 할당**을 위한 공간으로, malloc(), new 등으로 할당됩니다. **위쪽 방향으로 성장**하며 프로그래머가 직접 관리해야 합니다.

**Stack 영역**은 **함수 호출과 관련된 데이터**를 저장합니다. 지역변수, 함수 매개변수, 리턴 주소 등이 포함되며, **아래쪽 방향으로 성장**합니다.

### 2.3 Stack과 Heap의 동작 원리

**Stack 영역**은 실제로 자료구조의 **스택(LIFO)**과 동일하게 동작합니다. 함수가 호출될 때마다 해당 함수의 **활성화 레코드(Activation Record)**가 스택에 푸시되고, 함수가 종료되면 자동으로 팝됩니다.

```
함수 호출 스택의 예:
main() 호출 → [main의 활성화 레코드]
func_a() 호출 → [main] [func_a]
func_b() 호출 → [main] [func_a] [func_b]
func_b() 종료 → [main] [func_a]
func_a() 종료 → [main]
```

**Heap 영역**의 이름은 자료구조의 힙과 유사하지만, 실제로는 **동적 할당된 메모리들의 집합**입니다. 할당과 해제가 임의의 순서로 일어날 수 있어 메모리 단편화가 발생할 수 있습니다.

### 2.4 Stack vs Heap 성능 비교

**Stack**이 **Heap**보다 훨씬 빠른 이유:

1. **할당 방식**: Stack은 스택 포인터만 이동하면 되지만, Heap은 적절한 크기의 빈 공간을 찾아야 함
2. **접근 패턴**: Stack은 순차적 접근으로 CPU 캐시 효율이 높음
3. **메모리 관리**: Stack은 자동 해제되지만, Heap은 명시적 해제 필요
4. **단편화**: Stack은 단편화가 없지만, Heap은 단편화 발생 가능

### 2.5 스레드의 메모리 공유 방식

스레드들은 **Stack 영역만 독립적**으로 가지고, **Code, Data, Heap 영역은 모두 공유**합니다:

```
프로세스 주소공간에서 스레드 구성:
┌─────────────────┐
│ Thread1 Stack   │ ← 독립적
├─────────────────┤
│ Thread2 Stack   │ ← 독립적  
├─────────────────┤
│ Thread3 Stack   │ ← 독립적
├─────────────────┤
│      Heap       │ ← 공유 (동기화 필요)
├─────────────────┤
│      Data       │ ← 공유 (전역변수 등)
├─────────────────┤
│      Code       │ ← 공유 (실행 코드)
└─────────────────┘
```

이러한 공유 방식 때문에 스레드 간 통신은 빠르지만, **동기화 문제**에 주의해야 합니다.

### 2.6 메모리 크기의 결정과 조정

**Stack과 Heap의 크기는 동적으로 결정**됩니다:

- **컴파일 타임**: 대략적인 초기 크기 설정
- **런타임**: 필요에 따라 동적으로 확장
- **Stack**: 함수 호출 깊이와 지역변수 크기에 따라 결정
- **Heap**: 동적 할당 요청량에 따라 결정

사용자는 **ulimit 명령어**나 **컴파일러 옵션**을 통해 이러한 크기를 제한하거나 조정할 수 있습니다.

### 2.7 IPC 공유 메모리의 위치

**IPC(Inter-Process Communication)의 공유 메모리**는 각 프로세스의 가상 주소공간에서 **특별한 영역**에 매핑됩니다. 물리적으로는 같은 메모리를 가리키지만, 각 프로세스에서는 서로 다른 가상 주소로 접근할 수 있습니다.

이는 **프로세스 간 독립성을 유지하면서도 효율적인 데이터 공유**를 가능하게 하는 메커니즘입니다.

## 3. 스케줄러의 계층적 구조와 역할

### 3.1 3단계 스케줄러의 협력

운영체제는 **서로 다른 시간 단위**로 동작하는 3개의 스케줄러가 협력하여 프로세스를 관리합니다:

```
디스크의 프로그램들 → [장기 스케줄러] → Ready Queue → [단기 스케줄러] → CPU
     ↑                   (초~분 단위)      ↓           (ms 단위)
[중기 스케줄러] ←──────── Suspended Queue ←────────────────
   (초 단위)
```

### 3.2 장기 스케줄러 (Job Scheduler)

**역할**: 디스크에 있는 프로그램 중 어떤 것을 메모리로 가져와 프로세스로 만들지 결정

**특징**:
- **실행 빈도**: 매우 낮음 (초~분 단위)
- **목적**: 시스템의 **다중 프로그래밍 정도(Degree of Multiprogramming)** 조절
- **고려사항**: 메모리 사용량, CPU 사용률, I/O 집약적 vs CPU 집약적 프로그램의 균형

```
레스토랑 비유:
100명이 대기 → 주방 용량 고려하여 20명만 선택 → 대기실(Ready Queue)로 안내
장기 스케줄러 = 레스토랑 입구에서 손님을 선별하는 직원
```

### 3.3 단기 스케줄러 (CPU Scheduler)

**역할**: Ready Queue에 있는 프로세스 중 다음에 CPU를 사용할 프로세스 선택

**특징**:
- **실행 빈도**: 매우 높음 (밀리초 단위)
- **목적**: **CPU 이용률 최대화**와 응답 시간 최소화
- **알고리즘**: FCFS, SJF, Round Robin, Priority Scheduling 등

**스케줄링 알고리즘의 분류**:
- **Preemptive**: 실행 중인 프로세스를 강제로 중단시킬 수 있음
- **Non-preemptive**: 실행 중인 프로세스가 자발적으로 CPU를 반납할 때까지 대기

### 3.4 중기 스케줄러 (Swapper)

**역할**: 메모리 부족 시 일부 프로세스를 디스크로 내보내거나(Swap Out) 다시 메모리로 가져옴(Swap In)

**특징**:
- **실행 빈도**: 보통 (초 단위)
- **목적**: **메모리 관리**와 시스템 성능 개선
- **결과**: 프로세스가 Suspended 상태로 전환

```
호텔 비유:
객실 부족 → 일부 손님을 임시 숙소로 이동 → 객실 여유 생기면 다시 호텔로
중기 스케줄러 = 호텔 매니저가 객실 배정을 조정하는 역할
```

### 3.5 현대 운영체제의 스케줄러 사용

**현재 대부분의 운영체제는 단기 스케줄러를 중심으로 운영**됩니다:

- **장기 스케줄러**: 거의 사용하지 않음 (메모리가 충분해져서)
- **단기 스케줄러**: 핵심적으로 사용 (다양한 스케줄링 알고리즘 적용)
- **중기 스케줄러**: **가상 메모리 시스템**이 대부분의 역할을 대체

**Preemptive vs Non-preemptive의 제약**:
- **Non-preemptive**에서는 **Running → Ready 전이가 불가능**
- **Preemptive**에서는 모든 상태 전이가 가능

## 4. 컨텍스트 스위칭의 메커니즘

### 4.1 컨텍스트 스위칭의 필요성

**컨텍스트 스위칭**은 CPU가 한 프로세스에서 다른 프로세스로 실행 권한을 넘겨주는 과정입니다. 이는 **다중 프로그래밍**을 가능하게 하는 핵심 메커니즘으로, 사용자에게 여러 프로그램이 동시에 실행되는 것처럼 보이게 합니다.

**컨텍스트(Context)**란 프로세스의 현재 실행 상태를 나타내는 모든 정보를 의미하며, CPU 레지스터 값들, 프로그램 카운터, 스택 포인터, 메모리 관리 정보 등이 포함됩니다.

### 4.2 컨텍스트 스위칭 과정

```
1. 인터럽트 발생 (시간 할당량 종료, I/O 요청 등)
   ↓
2. 현재 프로세스 A의 컨텍스트를 PCB에 저장
   ↓
3. 스케줄러가 다음 실행할 프로세스 B 선택
   ↓
4. 프로세스 B의 컨텍스트를 PCB에서 읽어와 CPU에 복원
   ↓
5. 프로세스 B 실행 재개
```

이 과정에서 **순수한 오버헤드**가 발생하므로, 너무 자주 발생하면 시스템 성능이 저하됩니다.

### 4.3 프로세스 vs 스레드 컨텍스트 스위칭

메모리 공유 방식의 차이로 인해 **스위칭 비용이 크게 다릅니다**:

```c
// 프로세스 컨텍스트 스위칭
void process_context_switch(PCB *from, PCB *to) {
    // 1. 현재 프로세스의 모든 레지스터 저장
    save_all_registers(&from->cpu_context);
    
    // 2. 메모리 관리 유닛(MMU) 설정 변경 (큰 오버헤드!)
    switch_address_space(from->memory_info, to->memory_info);
    
    // 3. 새 프로세스의 레지스터 복원
    restore_all_registers(&to->cpu_context);
    
    // 4. 캐시와 TLB 무효화 (매우 큰 오버헤드!)
    flush_cache_and_tlb();
}

// 스레드 컨텍스트 스위칭  
void thread_context_switch(TCB *from, TCB *to) {
    // 1. 레지스터와 스택 포인터만 저장/복원
    save_registers(&from->registers);
    restore_registers(&to->registers);
    
    // 2. MMU 설정 변경 불필요 (메모리 공간 공유)
    // 3. 캐시 무효화 최소화
    // → 훨씬 빠른 전환!
}
```

**결과**: 스레드 컨텍스트 스위칭이 프로세스 컨텍스트 스위칭보다 **10-100배 빠릅니다**.

### 4.4 컨텍스트 스위칭 발생 시점

**자발적 컨텍스트 스위칭 (Voluntary)**:
- I/O 요청 시 (디스크 읽기/쓰기, 네트워크 통신 등)
- sleep() 함수 호출
- 동기화 객체 대기 (뮤텍스, 세마포어 등)
- 명시적 CPU 양보 (sched_yield())

**비자발적 컨텍스트 스위칭 (Involuntary)**:
- **시간 할당량(Time Quantum) 만료**
- 높은 우선순위 프로세스 등장
- 인터럽트 처리 후 스케줄링

### 4.5 커널 스택에서의 정보 저장

컨텍스트 스위칭 시 프로세스의 상태 정보는 해당 프로세스의 **커널 스택**에 저장됩니다. 이 정보는 **task_struct(Linux) 또는 PCB**와 연결되어 관리되며, 프로세스가 다시 실행될 때 정확히 복원됩니다.

**저장되는 정보의 형식**:
- CPU의 모든 범용 레지스터 값
- 프로그램 카운터 (다음에 실행할 명령어 주소)
- 스택 포인터와 베이스 포인터
- 플래그 레지스터 (상태 플래그들)
- 메모리 관리 관련 레지스터들

## 5. 시스템 통합과 성능 최적화

### 5.1 전체 시스템의 유기적 연결

지금까지 설명한 모든 개념들은 서로 밀접하게 연관되어 하나의 통합된 시스템을 구성합니다:

**프로세스 생성 과정**:
1. 프로그램 실행 요청 → 장기 스케줄러 판단
2. 메모리에 주소공간 할당 → PCB 생성
3. Ready Queue에 추가 → 단기 스케줄러가 CPU 할당
4. 실행 중 컨텍스트 스위칭으로 다른 프로세스와 교대 실행

**메모리 부족 시 대응**:
1. 중기 스케줄러 작동 → 일부 프로세스 Swap Out
2. 프로세스 상태가 Suspended로 변경
3. 메모리 여유 생성 → 새로운 프로세스 생성 가능
4. 필요시 Suspended 프로세스를 Swap In

### 5.2 성능 최적화 전략

**스케줄링 최적화**:
- 적절한 시간 할당량 설정 (너무 작으면 오버헤드 증가, 너무 크면 응답성 저하)
- I/O 집약적 프로세스와 CPU 집약적 프로세스의 균형
- 우선순위 기반 스케줄링으로 중요한 작업 우선 처리

**메모리 최적화**:
- 스택 사용 최소화 (지역변수 크기 제한, 재귀 깊이 제한)
- 동적 할당 최소화 (풀링 기법 사용)
- 메모리 접근 지역성 향상 (캐시 효율성 증대)

**컨텍스트 스위칭 최적화**:
- 멀티스레딩 활용 (프로세스 대신 스레드 사용)
- 적절한 동기화 메커니즘 선택
- CPU 친화성(Affinity) 설정으로 캐시 무효화 최소화

### 5.3 현대 시스템의 발전 방향

**다중 코어 시스템**에서는 진정한 병렬 처리가 가능하여 컨텍스트 스위칭 빈도를 줄이고 성능을 향상시킵니다. **가상화 기술**은 하나의 물리 시스템에서 여러 독립적인 운영체제를 실행할 수 있게 하며, **컨테이너 기술**은 가벼운 오버헤드로 애플리케이션 격리를 제공합니다.

## 핵심 개념 검증 문제

### 출제 빈도가 높은 핵심 문제들

**1. 프로세스와 스레드의 차이점과 각각의 컨텍스트 스위칭 비용 차이**

프로세스는 독립적인 메모리 공간을 가지므로 컨텍스트 스위칭 시 **MMU 설정 변경**과 **캐시/TLB 무효화**가 필요하여 높은 비용이 발생합니다. 반면 스레드는 메모리 공간을 공유하므로 **레지스터와 스택만 교환**하면 되어 훨씬 빠릅니다.

**2. 프로세스 주소공간의 각 영역별 특성과 Stack/Heap의 성장 방향**

**Code 영역**은 읽기 전용으로 프로그램 코드를 저장하고, **Data 영역**은 전역변수를 저장합니다. **Heap**은 위쪽으로 성장하며 동적 할당에 사용되고, **Stack**은 아래쪽으로 성장하며 함수 호출 정보를 **LIFO 방식**으로 관리합니다.

**3. 3단계 스케줄러의 역할과 현대 OS에서의 사용 현황**

**장기 스케줄러**는 다중 프로그래밍 정도를 조절하지만 현재는 거의 사용되지 않고, **단기 스케줄러**가 핵심적 역할을 담당하며, **중기 스케줄러**는 가상 메모리 시스템으로 대체되었습니다.

**4. 좀비 프로세스와 고아 프로세스의 발생 조건과 해결 방법**

**좀비 프로세스**는 자식이 종료되었지만 부모가 **wait()**를 호출하지 않아 PCB가 남아있는 상태이고, **고아 프로세스**는 부모가 먼저 죽어서 **init 프로세스(PID 1)**가 새로운 부모가 되는 프로세스입니다. 좀비는 부모가 wait() 호출로 해결하고, 고아는 init이 자동으로 정리합니다.

**5. 프로세스 상태 전이에서 Preemptive와 Non-preemptive 스케줄링의 차이**

**Non-preemptive 스케줄링**에서는 **Running → Ready 전이가 불가능**하며, 실행 중인 프로세스가 자발적으로 CPU를 반납할 때까지 기다려야 합니다. **Preemptive 스케줄링**에서는 시간 할당량 만료나 높은 우선순위 프로세스 등장 시 강제로 전환이 가능합니다.
